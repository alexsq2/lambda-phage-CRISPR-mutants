#script only works for gene L targets (478) unless "to_find" sequences are switched out



import xlsxwriter
import glob
import statistics

# take two sequences that are supposed to be reverse complement of each other, from stack overflow
def reverse_comp(in_sequence):
    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}
    seq = in_sequence
    reverse_complement = "".join(complement.get(base, base) for base in reversed(seq))
    return  reverse_complement

# takes in a list with file pairs and outputs a dictionary with info on each sequence
def file_pair_analysis(file_pair, random_list, control = False):

    sequence_lines = 0  # this represents the total number of valid sequences found, valid = R1R2 match
    seq_count_lib = {}  # defining this library to add sequences with info to

    R1_file = open(file_pair[0])
    R2_file = open(file_pair[1])

    lines_R1 = R1_file.readlines()
    lines_R2 = R2_file.readlines()

    print(len(lines_R1), 'lines in R1 file')
    print(len(lines_R2), 'lines in R2 file')

    line_count_r1 = 0
    line_count_r2 = 0

    same_length_sequences = 0
    matching_sequences = 0

    for line_num in range(len(lines_R1)):  # lines_R1 and R2 SHOULD have the same length
        temp_sequence_R1 = ''
        temp_sequence_R2 = ''
        if lines_R1[line_num].find(to_find1_R1) != -1 and lines_R1[line_num].find(to_find2_R1) != -1:
            temp_sequence_R1 = lines_R1[line_num][lines_R1[line_num].find(to_find1_R1) + len(to_find1_R1): lines_R1[line_num].find(to_find2_R1)]
            line_count_r1 += 1
            # print(temp_sequence_R1, 'r1 line')
            # print(temp_sequence_R1)

        if lines_R2[line_num].find(to_find1_R2) != -1 and lines_R2[line_num].find(to_find2_R2) != -1:
            temp_sequence_R2 = lines_R2[line_num][lines_R2[line_num].find(to_find1_R2) + len(to_find1_R2): lines_R2[line_num].find(to_find2_R2)]
            # print(temp_sequence_R2, 'r2 line')
            line_count_r2 += 1


        if len(temp_sequence_R1) == len(temp_sequence_R2) and len(temp_sequence_R1) > 20 and len(
                temp_sequence_R2) > 20:  # if they are same length, rev complement R2, match with R1
            same_length_sequences += 1

            if temp_sequence_R2 == reverse_comp(temp_sequence_R1) :
                # print('found R1R2 pair')
                matching_sequences += 1
                sequence_lines += 1
                # print(temp_sequence_R1)
                temp_sequence = temp_sequence_R2 # the final sequence used for analysis and comparison
                # print(temp_sequence)

                if temp_sequence not in seq_count_lib and len(temp_sequence) == len(perfect_target):
                    mm_count_temp = 0
                    mm_pos_1 = 'NA'
                    mm_bin_1 = 'NA'
                    mm_pos_2 = 'NA'
                    mm_bin_2 = 'NA'


                    for x in range(len(temp_sequence)):  # counting total mismatches
                        if temp_sequence[x] != perfect_target[x]:
                            mm_count_temp += 1
                            if mm_count_temp == 1:
                                mm_pos_1 = x
                                for region in target_regions:
                                    if x in target_regions[region]:
                                        mm_bin_1 = region
                            if mm_count_temp == 2:
                                mm_pos_2 = x
                                for region in target_regions:
                                    if x in target_regions[region]:
                                        mm_bin_2 = region
                    if mm_count_temp < 3:
                        seq_count_lib[temp_sequence] = {'count': 1, 'length': len(temp_sequence),
                             'mismatches': mm_count_temp, 'mismatch1': mm_pos_1,'mismatch2' : mm_pos_2,
                                    'mm_bin_1' : mm_bin_1, 'mm_bin_2': mm_bin_2, 'instances': 1}
                        seq_count_lib[temp_sequence]['random'] = temp_sequence in random_list

                    if mm_count_temp > 3 and temp_sequence in random_list:
                        seq_count_lib[temp_sequence] = {'count': 1, 'length': len(temp_sequence),
                                                        'mismatches': mm_count_temp, 'mismatch1': mm_pos_1,
                                                        'mismatch2': mm_pos_2,
                                                        'mm_bin_1': mm_bin_1, 'mm_bin_2': mm_bin_2, 'instances': 1}
                        seq_count_lib[temp_sequence]['random'] = temp_sequence in random_list

                elif len(temp_sequence) == len(perfect_target):
                    seq_count_lib[temp_sequence]['count'] = seq_count_lib[temp_sequence]['count'] + 1

    print(matching_sequences, 'matching sequences')
    print(sequence_lines)
    print(same_length_sequences, 'same length sequences')


    for item in seq_count_lib:
        seq_count_lib[item]['fraction'] = seq_count_lib[item]['count'] / matching_sequences

        if seq_count_lib[item]['mm_bin_1'] != 'NA' and seq_count_lib[item]['mm_bin_2'] != 'NA':
            seq_count_lib[item]['mm_combo'] = seq_count_lib[item]['mm_bin_1'] + ' + ' + seq_count_lib[item]['mm_bin_2']
        elif seq_count_lib[item]['mm_bin_1'] != 'NA' and seq_count_lib[item]['mismatches'] == 1:
            seq_count_lib[item]['mm_combo'] = seq_count_lib[item]['mm_bin_1']

        elif seq_count_lib[item]['mismatches'] == 0:
            seq_count_lib[item]['mm_combo'] = "perfect"



    if control == False:
        if 'Supercoil' in file_pair[0] and 'Supercoil' in file_pair[1]:
            control_lib_typed = analysis_control_lib_combined_Supercoil
        if 'Nicked' in file_pair[0] and 'Nicked' in file_pair[1]:
            control_lib_typed = analysis_control_lib_combined_Nicked

        for item in seq_count_lib:
            if item in control_lib_typed:
                seq_count_lib[item]['enrichment'] = seq_count_lib[item]['fraction'] / control_lib_typed[item]['fraction']
            else:
                seq_count_lib[item]['enrichment'] = 1

        for item in seq_count_lib:
            if item in control_lib_typed:
                seq_count_lib[item]['z_numerator'] = seq_count_lib[item]['fraction'] - control_lib_typed[item]['fraction']
            else:
                seq_count_lib[item]['z_numerator'] = 0
        #now making a z-score value using stdev of all z_numberators

        fraction_sums = []
        for item in seq_count_lib:
            fraction_sums.append(seq_count_lib[item]['fraction'])
        standard_dev_exp = statistics.stdev(fraction_sums)

        for item in seq_count_lib:
            seq_count_lib[item]['z-score'] = seq_count_lib[item]['z_numerator'] / standard_dev_exp

#compensating for the enrichment of random sequences which should not be cut at all
        if 'Supercoil' in file_pair[0] and 'Supercoil' in file_pair[1]:
            random_sum = 0
            random_count = 0
            random_average = 0
            for item in seq_count_lib:
                if seq_count_lib[item]['random'] == True:
                    random_sum += seq_count_lib[item]['enrichment']
                    random_count +=1
            random_average = random_sum/random_count
            print(random_average, 'random average')

            for item in seq_count_lib:  # NOT correcting enrichment of random sequences because we're using random sequences to correct others
                if seq_count_lib[item]['random'] == False:
                    seq_count_lib[item]['enrichment'] = seq_count_lib[item]['enrichment'] / random_average
    return seq_count_lib


#XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#start of actual analysis
#data that is specific for the target being analyzed
workbook = xlsxwriter.Workbook('(top) data_L_4mg_library.xlsx')

perfect_target = 'TTTGTACTGTCCACGCCGACGGAA' #FORWARD orientation

to_find1_R1 = 'CCGAGCTTGACCA'  #extract the target sequence between these two sequences from the R1 file
to_find2_R1 = 'ATCCTGAAGCAC'

to_find1_R2 = 'AGGAT'  #extract the target sequence between these two sequences from the R2 file
to_find2_R2 = 'TGGTC'
random_sequences_list = ['GCATTCTTATTAATACATTTGAAA','CGCGCCCAACTGACGCTAGGCAAG','TCAGTGCAGGCTCCCGTGTTAGGA','TAAGGGTAAACATACAAGTCGATA','CATCCAGCACTCTACGGTTCCTCC']

complement_list = [['A', 'T'], ['T', 'A'], ['C', 'G'], ['G', 'C']]
target_regions = {'PAM': [0,1,2,3], 'seed': [4,5,6,7,8,9], 'mid': [10,11,12,13,14,15,16], 'distal':[17,18,19,20,21,22,23] }

# selecting files for control sample, which the experimental samples will be compared with


control_file_list_Supercoil = []
control_file_list_Nicked = []
control_file_list_Supercoil += glob.glob('L_Fn_Supercoil_10_Control*')
control_file_list_Nicked += glob.glob('L_Fn_Nicked_10_Control*')
control_file_list_Supercoil_pairs = []
control_file_list_Nicked_pairs = []
control_list_half_Supercoil = int(len(control_file_list_Supercoil) / 2)
control_list_half_Nicked = int(len(control_file_list_Nicked) / 2)

for x in range(control_list_half_Supercoil):
    control_file_list_Supercoil_pairs.append([control_file_list_Supercoil[2 * x]] + [control_file_list_Supercoil[2 * x + 1]])
for x in range(control_list_half_Nicked):
    control_file_list_Nicked_pairs.append([control_file_list_Nicked[2 * x]] + [control_file_list_Nicked[2 * x + 1]])




analysis_control_lib_combined_Supercoil = {}
analysis_control_lib_combined_Nicked = {}

#preparing control supercoil files
for pair in control_file_list_Supercoil_pairs:
    control_lib = file_pair_analysis(pair, random_sequences_list, control = True) #analyzing control files, making library
    if len(control_lib) > 2400:
        for item in control_lib:
            if item in analysis_control_lib_combined_Supercoil:
                analysis_control_lib_combined_Supercoil[item]['fraction'] += control_lib[item]['fraction']
                analysis_control_lib_combined_Supercoil[item]['instances'] += 1
            else:
                analysis_control_lib_combined_Supercoil[item] = control_lib[item]
for item in analysis_control_lib_combined_Supercoil:
    analysis_control_lib_combined_Supercoil[item]['fraction'] = analysis_control_lib_combined_Supercoil[item]['fraction']/analysis_control_lib_combined_Supercoil[item]['instances']

#preparing control nicked files
for pair in control_file_list_Nicked_pairs:
    control_lib = file_pair_analysis(pair, random_sequences_list, control = True) #analyzing control files, making library
    if len(control_lib) > 2400:
        for item in control_lib:
            if item in analysis_control_lib_combined_Nicked:
                analysis_control_lib_combined_Nicked[item]['fraction'] += control_lib[item]['fraction']
                analysis_control_lib_combined_Nicked[item]['instances'] += 1
            else:
                analysis_control_lib_combined_Nicked[item] = control_lib[item]
for item in analysis_control_lib_combined_Nicked:
    analysis_control_lib_combined_Nicked[item]['fraction'] = analysis_control_lib_combined_Nicked[item]['fraction']/analysis_control_lib_combined_Nicked[item]['instances']






file_list = []
file_list += glob.glob('L_As_Supercoil_1_1*')
file_list += glob.glob('L_As_Supercoil_2_1*')
file_list += glob.glob('L_As_Supercoil_5_1*')
file_list += glob.glob('L_As_Supercoil_10_1*')
file_list += glob.glob('L_Fn_Supercoil_1_1*')
file_list += glob.glob('L_Fn_Supercoil_2_1*')
file_list += glob.glob('L_Fn_Supercoil_5_1*')
file_list += glob.glob('L_Fn_Supercoil_10_1*')
file_list += glob.glob('L_Lb_Supercoil_1_1*')
file_list += glob.glob('L_Lb_Supercoil_2_1*')
file_list += glob.glob('L_Lb_Supercoil_5_1*')
file_list += glob.glob('L_Lb_Supercoil_10_1*')
#
file_list += glob.glob('L_As_Supercoil_1_30*')
file_list += glob.glob('L_As_Supercoil_2_30*')
file_list += glob.glob('L_As_Supercoil_5_30*')
file_list += glob.glob('L_As_Supercoil_10_30*')
file_list += glob.glob('L_Fn_Supercoil_1_30*')
file_list += glob.glob('L_Fn_Supercoil_2_30*')
file_list += glob.glob('L_Fn_Supercoil_5_30*')
file_list += glob.glob('L_Fn_Supercoil_10_30*')
file_list += glob.glob('L_Lb_Supercoil_1_30*')
file_list += glob.glob('L_Lb_Supercoil_2_30*')
file_list += glob.glob('L_Lb_Supercoil_5_30*')
file_list += glob.glob('L_Lb_Supercoil_10_30*')
#
file_list += glob.glob('L_As_Nicked_1_1*')
file_list += glob.glob('L_As_Nicked_2_1*')
file_list += glob.glob('L_As_Nicked_5_1*')
file_list += glob.glob('L_As_Nicked_10_1*')
file_list += glob.glob('L_Fn_Nicked_1_1*')
file_list += glob.glob('L_Fn_Nicked_2_1*')
file_list += glob.glob('L_Fn_Nicked_5_1*')
file_list += glob.glob('L_Fn_Nicked_10_1*')
file_list += glob.glob('L_Lb_Nicked_1_1*')
file_list += glob.glob('L_Lb_Nicked_2_1*')
file_list += glob.glob('L_Lb_Nicked_5_1*')
file_list += glob.glob('L_Lb_Nicked_10_1*')
#
file_list += glob.glob('L_As_Nicked_1_30*')
file_list += glob.glob('L_As_Nicked_2_30*')
file_list += glob.glob('L_As_Nicked_5_30*')
file_list += glob.glob('L_As_Nicked_10_30*')
file_list += glob.glob('L_Fn_Nicked_1_30*')
file_list += glob.glob('L_Fn_Nicked_2_30*')
file_list += glob.glob('L_Fn_Nicked_5_30*')
file_list += glob.glob('L_Fn_Nicked_10_30*')
file_list += glob.glob('L_Lb_Nicked_1_30*')
file_list += glob.glob('L_Lb_Nicked_2_30*')
file_list += glob.glob('L_Lb_Nicked_5_30*')
file_list += glob.glob('L_Lb_Nicked_10_30*')


file_list_length_half = int(len(file_list) / 2)
total_file_list_pairs = []
for x in range(file_list_length_half):
    total_file_list_pairs.append([file_list[2 * x]] + [file_list[2 * x + 1]])
print(total_file_list_pairs)
all_sample_info = [] # this will be written on the firstsheet containing info for all of the samples processed

custom_format = workbook.add_format({'num_format': ';;;'})

#making worksheets containing info from all of the samples
worksheet_bar_graph_values = workbook.add_worksheet('bar graphs')
worksheet_all = workbook.add_worksheet('All info')
row=0
column = 0
for item in total_file_list_pairs:
    worksheet_all.write(row,column,item[0])
    worksheet_all.write(row,column+1,item[1])
    row += 1




# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#analysis for change in enrichment with magnesium
#deal with 12 files at a time, pool three replicates for each mg, then combine mg conditions

master_4mg_lib = {} # this will contain enrichment values for 4 mg concentrations for each sequence
#sequences have to be in all magnesium concentrations, not necessarily all 3 replicates

replicate_trip_count = 0
four_mg_condition_count = 0
list_of_trip_dictionaries = []
triplicate_dict_combined = {}
list_of_four_mg_dicts = []
list_trip_dicts_enrichment = [] # will be used for plotting raw enrichment values for each 1mM Mg sample
bar_list_trip_dictionaries = []
#XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#combining four magnesium concentrations into heat map
for pair in total_file_list_pairs:

    if replicate_trip_count == 0:
        list_of_trip_dictionaries = []
    if replicate_trip_count != 3:
        list_of_trip_dictionaries.append(file_pair_analysis(pair, random_sequences_list))
    replicate_trip_count += 1

    if replicate_trip_count == 3:
        bar_list_trip_dictionaries.append(  [list_of_trip_dictionaries,pair[0]]  )
        for dict in list_of_trip_dictionaries:
            if len(dict) > 500:
                for item in dict:
                    if item not in triplicate_dict_combined:
                        triplicate_dict_combined[item] = dict[item]
                    else:
                        triplicate_dict_combined[item]['instances'] += 1
                        triplicate_dict_combined[item]['enrichment'] += dict[item]['enrichment']
        for item in triplicate_dict_combined:
            triplicate_dict_combined[item]['enrichment'] = triplicate_dict_combined[item]['enrichment']/triplicate_dict_combined[item]['instances']
        # print('COMBINED TRIPLICATES DICTS',triplicate_dict_combined)
        list_of_four_mg_dicts.append(triplicate_dict_combined)
        #adding only 1mM samples to list_all_trip_dictionaries
        # if ('Nicked_1' in pair[0] and 'Nicked_1' in pair[1]) or ('Supercoil_1' in pair[0] and 'Supercoil_1' in pair[1]) :
        list_trip_dicts_enrichment.append([triplicate_dict_combined,pair])
        print(len(list_of_trip_dictionaries), 'trip dictionaries')
        #resetting all triplicate stuff
        replicate_trip_count = 0
        list_of_trip_dictionaries = []
        triplicate_dict_combined = {}
        four_mg_condition_count += 1

        if four_mg_condition_count == 4:
            four_mg_condition_count = 0
            worksheet_4mg = workbook.add_worksheet(pair[0][:22])
            four_mg_dict = {}
            for item in list_of_four_mg_dicts[0]:
                in_all = True
                for dict in list_of_four_mg_dicts:
                    if item not in dict:
                        in_all = False
                if in_all == True:
                    four_mg_dict[item] = {'mg_list' : [], 'mg_sum': 'NA'}
                    for dict in list_of_four_mg_dicts:
                        four_mg_dict[item]['mg_list'].append(dict[item]['enrichment'])

            for item in four_mg_dict: #calculating change in enrichment with increasing magnesium
                enrich_change_sum = 0
                for index in range(len(four_mg_dict[item]['mg_list']) -1):
                    if four_mg_dict[item]['mg_list'][0] / four_mg_dict[item]['mg_list'][index +1] > 1:
                        enrich_change_sum += four_mg_dict[item]['mg_list'][0] / four_mg_dict[item]['mg_list'][index +1]
                    else:
                        enrich_change_sum += (-1)*(four_mg_dict[item]['mg_list'][index +1] / four_mg_dict[item]['mg_list'][0] )
                # enrich_change_average = enrich_change_sum/(len(four_mg_dict[item])) #generalizes to more or less mg conditions
                four_mg_dict[item]['mg_sum'] = enrich_change_sum

            list_of_four_mg_dicts = []
            row=0
            for item in four_mg_dict:
                column = 0
                worksheet_4mg.write(row, column, item)
                column += 1
                for mg in four_mg_dict[item]['mg_list']:
                    worksheet_4mg.write(row,column,mg)
                    column += 1

                worksheet_4mg.write(row,column,four_mg_dict[item]['mg_sum'])
                row += 1


            for item in four_mg_dict: #classifying every sequence in this dictionary with the mismatch positions
                mm_count_temp = 0
                mm_pos_1 = 'NA'
                mm_bin_1 = 'NA'
                mm_pos_2 = 'NA'
                mm_bin_2 = 'NA'

                for x in range(len(item)):  # counting total mismatches
                    if item[x] != perfect_target[x]:
                        mm_count_temp += 1
                        if mm_count_temp == 1:
                            mm_pos_1 = x
                            for region in target_regions:
                                if x in target_regions[region]:
                                    mm_bin_1 = region
                        if mm_count_temp == 2:
                            mm_pos_2 = x
                            for region in target_regions:
                                if x in target_regions[region]:
                                    mm_bin_2 = region
                if mm_count_temp < 3:
                    four_mg_dict[item]['length'] = len(item)
                    four_mg_dict[item]['mismatches'] = mm_count_temp
                    four_mg_dict[item]['mismatch1'] = mm_pos_1
                    four_mg_dict[item]['mismatch2'] = mm_pos_2
                    four_mg_dict[item]['mm_bin_1'] = mm_bin_1
                    four_mg_dict[item]['mm_bin_2'] = mm_bin_2
                    four_mg_dict[item]['random'] = item in random_sequences_list


                if mm_count_temp > 3 and item in random_sequences_list:
                    four_mg_dict[item]['length'] = len(item)
                    four_mg_dict[item]['mismatches'] = mm_count_temp
                    four_mg_dict[item]['mismatch1'] = mm_pos_1
                    four_mg_dict[item]['mismatch2'] = mm_pos_2
                    four_mg_dict[item]['mm_bin_1'] = mm_bin_1
                    four_mg_dict[item]['mm_bin_2'] = mm_bin_2
                    four_mg_dict[item]['random'] = item in random_sequences_list



            #making 2D heat map with mg dependent enrichment change
            grid24_list = []

            for x in range(24):
                zero_list = []
                for x in range(24):
                    zero_list.append([0,0])
                grid24_list.append(zero_list)
            # print(grid24_list)


            row = 8
            column = 7
            for num in range(-4, 21):
                if num != 0:
                    worksheet_4mg.write(row, column, num)
                    row += 1

            row = 7
            column = 8
            for num in range(-4, 21):
                if num != 0:
                    worksheet_4mg.write(row, column, num)
                    column += 1

#making 2D heat map for double mismatches
            for item in four_mg_dict:
                if four_mg_dict[item]['mismatch1'] != 'NA' and four_mg_dict[item]['mismatch2'] != 'NA':
                    grid24_list[four_mg_dict[item]['mismatch1']][four_mg_dict[item]['mismatch2']][0] += four_mg_dict[item]['mg_sum']
                    grid24_list[four_mg_dict[item]['mismatch1']][four_mg_dict[item]['mismatch2']][1] += 1

            for x in range(24):
                for y in range(24):
                    if grid24_list[x][y][1] > 0:
                        grid24_list[x][y][0] = grid24_list[x][y][0]/grid24_list[x][y][1]
                # print(grid24_list)

            grid24_values_list = []
            for x in range(24):
                for y in range(24):
                    grid24_values_list.append(grid24_list[x][y][0])
            min_value_heat_map = min(grid24_values_list)
            max_value_heat_map = max(grid24_values_list)
            range_heat_map = max(-min_value_heat_map,max_value_heat_map)

            for row in range(len(grid24_list)):
                for column in range(len(grid24_list)):
                    worksheet_4mg.write(row + 8, column+8, grid24_list[row][column][0], custom_format)
            for num in range(200):
                worksheet_4mg.set_row(num, 14.5)
            worksheet_4mg.set_column(0, 100, 2.18)

            worksheet_4mg.conditional_format(8, 8, 32, 32,
                                             {'type': '3_color_scale', 'min_color': 'red', 'mid_color': 'white',  'max_color': 'blue',
                                              'min_value': -1*range_heat_map, 'mid_value': 0,'max_value': range_heat_map,
                                              'min_type': 'num','mid_type': 'num','max_type': 'num',})

#making heat map for single mismatches only
            perfect_target_list = list(perfect_target)
            row = 9
            column = 35
            for base in perfect_target_list:
                worksheet_4mg.write(row, column, base)
                column += 1
            base_num_dict = {'A': 0, 'T': 1, 'C': 2, 'G': 3}
            for item in base_num_dict:
                worksheet_4mg.write(base_num_dict[item] + 10, 34, item)
            row = 10
            column = 35
            for item in four_mg_dict:
                if four_mg_dict[item]['mismatches'] == 1:
                    if four_mg_dict[item]['mismatch1'] != 'NA':
                        worksheet_4mg.write(base_num_dict[item[four_mg_dict[item]['mismatch1']]] + row,
                                        four_mg_dict[item]['mismatch1'] + column,
                                        four_mg_dict[item]['mg_sum'],
                                        custom_format)

            worksheet_4mg.conditional_format(10, 35, 15, 60,
                                             {'type': '3_color_scale', 'min_color': 'red', 'mid_color': 'white',
                                              'max_color': 'blue',
                                              'min_value': -1 * range_heat_map, 'mid_value': 0,
                                              'max_value': range_heat_map,
                                              'min_type': 'num', 'mid_type': 'num', 'max_type': 'num', })

#XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#writing enrichment values for 1mM samples only
for dict in list_trip_dicts_enrichment: # this has 2 item lists with index 0 as the dict, and 1 as the file name
    worksheet_enrich_only = workbook.add_worksheet(dict[1][0][:22]+'enrich')
    sample_dict = dict[0]
    #truly embarrassing if I don't need to repeat this sequence classification, waste of time
    # for item in sample_dict:
    #
    #     mm_count_temp = 0
    #     mm_pos_1 = 'NA'
    #     mm_bin_1 = 'NA'
    #     mm_pos_2 = 'NA'
    #     mm_bin_2 = 'NA'
    #
    #     for x in range(len(item)):  # counting total mismatches
    #         if item[x] != perfect_target[x]:
    #             mm_count_temp += 1
    #             if mm_count_temp == 1:
    #                 mm_pos_1 = x
    #                 for region in target_regions:
    #                     if x in target_regions[region]:
    #                         mm_bin_1 = region
    #             if mm_count_temp == 2:
    #                 mm_pos_2 = x
    #                 for region in target_regions:
    #                     if x in target_regions[region]:
    #                         mm_bin_2 = region
    #     if mm_count_temp < 3:
    #         sample_dict[item]['length'] = len(item)
    #         sample_dict[item]['mismatches'] = mm_count_temp
    #         sample_dict[item]['mismatch1'] = mm_pos_1
    #         sample_dict[item]['mismatch2'] = mm_pos_2
    #         sample_dict[item]['mm_bin_1'] = mm_bin_1
    #         sample_dict[item]['mm_bin_2'] = mm_bin_2
    #         sample_dict[item]['random'] = item in random_sequences_list
    #
    #     if mm_count_temp > 3 and item in random_sequences_list:
    #         sample_dict[item]['length'] = len(item)
    #         sample_dict[item]['mismatches'] = mm_count_temp
    #         sample_dict[item]['mismatch1'] = mm_pos_1
    #         sample_dict[item]['mismatch2'] = mm_pos_2
    #         sample_dict[item]['mm_bin_1'] = mm_bin_1
    #         sample_dict[item]['mm_bin_2'] = mm_bin_2
    #         sample_dict[item]['random'] = item in random_sequences_list

# making 2D heat map with mg dependent enrichment change
    grid24_list = []

    for x in range(24):
        zero_list = []
        for x in range(24):
            zero_list.append([0, 0])
        grid24_list.append(zero_list)
    # print(grid24_list)

    row = 8
    column = 7
    for num in range(-4, 21):
        if num != 0:
            worksheet_enrich_only.write(row, column, num)
            row += 1

    row = 7
    column = 8
    for num in range(-4, 21):
        if num != 0:
            worksheet_enrich_only.write(row, column, num)
            column += 1

    # making 2D heat map for double mismatches
    for item in sample_dict:
        if sample_dict[item]['mismatch1'] != 'NA' and sample_dict[item]['mismatch2'] != 'NA':
            grid24_list[sample_dict[item]['mismatch1']][sample_dict[item]['mismatch2']][0] += sample_dict[item]['enrichment']
            grid24_list[sample_dict[item]['mismatch1']][sample_dict[item]['mismatch2']][1] += 1

    for x in range(24):
        for y in range(24):
            if grid24_list[x][y][1] > 0:
                grid24_list[x][y][0] = grid24_list[x][y][0] / grid24_list[x][y][1]
        # print(grid24_list)

    grid24_values_list = []
    for x in range(24):
        for y in range(24):
            grid24_values_list.append(grid24_list[x][y][0])
    min_value_heat_map = min(grid24_values_list)
    max_value_heat_map = max(grid24_values_list)
    range_heat_map = max(-min_value_heat_map, max_value_heat_map)

    for row in range(len(grid24_list)):
        for column in range(len(grid24_list)):
            worksheet_enrich_only.write(row + 8, column + 8, grid24_list[row][column][0], custom_format)
    for num in range(200):
        worksheet_enrich_only.set_row(num, 14.5)
    worksheet_enrich_only.set_column(0, 100, 2.18)

    worksheet_enrich_only.conditional_format(8, 8, 32, 32,
                                     {'type': '3_color_scale', 'min_color': 'red', 'mid_color': 'white',
                                      'max_color': 'blue',
                                      'min_value': -1 * range_heat_map, 'mid_value': 0, 'max_value': range_heat_map,
                                      'min_type': 'num', 'mid_type': 'num', 'max_type': 'num', })

    # making heat map for single mismatches only
    perfect_target_list = list(perfect_target)
    row = 9
    column = 35
    for base in perfect_target_list:
        worksheet_enrich_only.write(row, column, base)
        column += 1
    base_num_dict = {'A': 0, 'T': 1, 'C': 2, 'G': 3}
    for item in base_num_dict:
        worksheet_enrich_only.write(base_num_dict[item] + 10, 34, item)
    row = 10
    column = 35
    range_heat_map_singles = 0
    for item in sample_dict:
        if sample_dict[item]['mismatches'] == 1:
            if sample_dict[item]['mismatch1'] != 'NA':
                worksheet_enrich_only.write(base_num_dict[item[sample_dict[item]['mismatch1']]] + row,
                                    sample_dict[item]['mismatch1'] + column,
                                    sample_dict[item]['enrichment'],
                                    custom_format)
                if sample_dict[item]['enrichment'] > range_heat_map_singles:
                    range_heat_map_singles = sample_dict[item]['enrichment']

    worksheet_enrich_only.conditional_format(10, 35, 15, 60,
                                     {'type': '3_color_scale', 'min_color': 'red', 'mid_color': 'white',
                                      'max_color': 'blue',
                                      'min_value': -1 * range_heat_map_singles, 'mid_value': 0,
                                      'max_value': range_heat_map_singles,
                                      'min_type': 'num', 'mid_type': 'num', 'max_type': 'num', })

#################################################################
#making values for bar graphs
#first make a dictionary with all of the mm_combos, average and standard deviation

#need to calculate average enrichment for each category for each triplicate
#then pool the averages for each category and calculate the average again and STDEV

print(len(bar_list_trip_dictionaries))
row = 1
column = 1
for triple in bar_list_trip_dictionaries:
    triplicate_categories_dict = {}
    triple_count = 0
    for dict in triple[0]:
        single_dict_categories = {}
        for sequence in dict:
            if dict[sequence]['mm_combo'] not in single_dict_categories:
                single_dict_categories[dict[sequence]['mm_combo']] = [   dict[sequence]['enrichment']   ]
            else:
                single_dict_categories[dict[sequence]['mm_combo']].append( dict[sequence]['enrichment'])
        single_dict_average = {}


        for category in single_dict_categories:
            if len(single_dict_categories[category]) != 1:
                single_dict_average[category] = statistics.mean(single_dict_categories[category])
            else:
                single_dict_average[category] = single_dict_categories[category][0]
        triplicate_list_sortable = []
        for item in single_dict_average:
            triplicate_list_sortable.append([item,single_dict_average[item]])
        triplicate_list_sortable.sort()
        if triple_count == 0:
            for item in triplicate_list_sortable:
                worksheet_bar_graph_values.write(row, 0, item[0])
                row += 1
            row = 1
            worksheet_bar_graph_values.write(0, column, triple[1][0:18])
        for category in triplicate_list_sortable:
            worksheet_bar_graph_values.write(row, column, category[1])
            row += 1
        row = 1
        column += 1
        triple_count += 1
        if triple_count == 3:
            triple_count = 0


workbook.close()
